{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importing the necessary libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "try: \n",
    "    [tf.config.experimental.set_memory_growth(gpu, True) for gpu in tf.config.experimental.list_physical_devices(\"GPU\")]\n",
    "except: \n",
    "    pass\n",
    "\n",
    "import os\n",
    "import typing\n",
    "import requests\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from mltu.preprocessors import ImageReader\n",
    "from mltu.transformers import ImageResizer, LabelIndexer, LabelPadding, ImageShowCV2\n",
    "from mltu.augmentors import RandomBrightness, RandomRotate, RandomErodeDilate, RandomSharpen\n",
    "from mltu.annotations.images import CVImage\n",
    "from mltu.tensorflow.dataProvider import DataProvider\n",
    "from mltu.tensorflow.losses import CTCloss\n",
    "from mltu.tensorflow.callbacks import Model2onnx, TrainLogger\n",
    "from mltu.tensorflow.metrics import CERMetric, WERMetric\n",
    "from mltu.configs import BaseModelConfigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authentication details for downloading the dataset\n",
    "\n",
    "USER = \"daniel.byiringiro@ashesi.edu.gh\"\n",
    "PASSWORD = \"December@2020\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCII dataset downloaded successfully.\n",
      "Sentences dataset downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# download the ASCII dataset and the sentences dataset\n",
    "\n",
    "# URL of the files to download\n",
    "ascii_url = \"https://fki.tic.heia-fr.ch/DBs/iamDB/data/ascii.tgz\"\n",
    "sentences_url = \"https://fki.tic.heia-fr.ch/DBs/iamDB/data/sentences.tgz\"\n",
    "\n",
    "# Session to handle cookies\n",
    "session = requests.Session()\n",
    "\n",
    "# Perform login\n",
    "login_url = \"https://fki.tic.heia-fr.ch/login\"\n",
    "login_payload = {\"email\": USER, \"password\": PASSWORD}\n",
    "login_response = session.post(login_url, data=login_payload)\n",
    "\n",
    "if \"error\" in login_response.text:\n",
    "    print(\"Login failed.\")\n",
    "else:\n",
    "    # Download the ASCII dataset\n",
    "    ascii_response = session.get(ascii_url)\n",
    "    if ascii_response.status_code == 200:\n",
    "        with open(\"ascii.tgz\", \"wb\") as file:\n",
    "            file.write(ascii_response.content)\n",
    "        print(\"ASCII dataset downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download the ASCII dataset. Status code: {ascii_response.status_code}\")\n",
    "\n",
    "    # Download the sentences dataset\n",
    "    sentences_response = session.get(sentences_url)\n",
    "    if sentences_response.status_code == 200:\n",
    "        with open(\"sentences.tgz\", \"wb\") as file:\n",
    "            file.write(sentences_response.content)\n",
    "        print(\"Sentences dataset downloaded successfully.\")\n",
    "    else:\n",
    "        print(f\"Failed to download the sentences dataset. Status code: {sentences_response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the downloaded files\n",
    "\n",
    "ascii_file = \"ascii.tgz\"\n",
    "sentences_file = \"sentences.tgz\"\n",
    "\n",
    "ascii_extracted_folder = \"ascii\"\n",
    "sentences_extracted_folder = \"sentences\"\n",
    "\n",
    "if not os.path.exists(ascii_extracted_folder):\n",
    "    print(\"Extracting the ASCII dataset...\")\n",
    "    with tarfile.open(ascii_file, \"r:gz\") as tar:\n",
    "        tar.extractall(path = ascii_extracted_folder)\n",
    "    print(\"ASCII dataset extracted successfully.\")\n",
    "    \n",
    "if not os.path.exists(sentences_extracted_folder):\n",
    "    print(\"Extracting the sentences dataset...\")\n",
    "    with tarfile.open(sentences_file, \"r:gz\") as tar:\n",
    "        tar.extractall(path = sentences_extracted_folder)\n",
    "    print(\"Sentences dataset extracted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASCII dataset file removed.\n",
      "Sentences dataset file removed.\n"
     ]
    }
   ],
   "source": [
    "# remove the downloaded files\n",
    "\n",
    "if os.path.exists(ascii_file):\n",
    "    os.remove(ascii_file)\n",
    "    print(\"ASCII dataset file removed.\")\n",
    "\n",
    "if os.path.exists(sentences_file):\n",
    "    os.remove(sentences_file)\n",
    "    print(\"Sentences dataset file removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/16777 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16777/16777 [00:02<00:00, 6226.69it/s]\n"
     ]
    }
   ],
   "source": [
    "# prepare the dataset\n",
    "\n",
    "ascii_sentences_file = os.path.join(ascii_extracted_folder, \"sentences.txt\")\n",
    "sentences_folder = sentences_extracted_folder   \n",
    "\n",
    "# read the sentences file\n",
    "\n",
    "dataset, vocab, maximum_length = [], set(), 0   \n",
    "\n",
    "words = open(ascii_sentences_file).readlines()\n",
    "\n",
    "for line in tqdm(words):\n",
    "    \n",
    "    if line.startswith(\"#\"):\n",
    "        continue\n",
    "    \n",
    "    line = line.split(\" \")\n",
    "    \n",
    "    subfolder = line[0].split(\"-\")[0]\n",
    "    sub_subfolder = line[0].split(\"-\")[:2]\n",
    "    sub_subfolder = \"-\".join(sub_subfolder)\n",
    "    filename = line[0] + \".png\"\n",
    "    \n",
    "    image_path = os.path.join(sentences_folder, subfolder, sub_subfolder, filename)\n",
    "    \n",
    "    text = \" \".join(line[9:])\n",
    "    text = text.replace(\"|\", \" \")\n",
    "    text = text.replace(\"\\n\", \"\")\n",
    "    \n",
    "    # check if the image exists\n",
    "    \n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Image {image_path} does not exist.\")\n",
    "        continue\n",
    "    \n",
    "    # check if the text is empty\n",
    "    \n",
    "    if len(text) == 0:\n",
    "        print(f\"Text is empty for image {image_path}.\")\n",
    "        continue\n",
    "    \n",
    "    dataset.append([image_path, text])\n",
    "    vocab.update(list(text))\n",
    "    maximum_length = max(maximum_length, len(text))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a configuration class\n",
    "\n",
    "class ModelConfigs(BaseModelConfigs):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model_path = os.path.join(\"models\", datetime.strftime(datetime.now(), \"%Y%m%d%H%M\"))\n",
    "        self.vocab = \"\"\n",
    "        self.height = 96\n",
    "        self.width = 1408\n",
    "        self.max_text_length = 0\n",
    "        self.batch_size = 32\n",
    "        self.learning_rate = 0.0005\n",
    "        self.train_epochs = 1000\n",
    "        self.train_workers = 20\n",
    "        self.channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a ModelConfigs object to store the configurations and update the values\n",
    "\n",
    "configs = ModelConfigs()\n",
    "\n",
    "# update the vocab, maximum text length\n",
    "\n",
    "configs.vocab = \"\".join(vocab)\n",
    "configs.max_text_length = maximum_length\n",
    "configs.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data provider for the dataset\n",
    "\n",
    "data_provider = DataProvider(\n",
    "    dataset = dataset,\n",
    "    skip_validation = True,\n",
    "    batch_size = configs.batch_size,\n",
    "    data_preprocessors = [ImageReader(CVImage)],\n",
    "    transformers = [\n",
    "        ImageResizer(height = configs.height, width = configs.width, keep_aspect_ratio=True),\n",
    "        LabelIndexer(vocab = configs.vocab),\n",
    "        LabelPadding(max_word_length = configs.max_text_length, padding_value=len(configs.vocab)),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset into training and validation sets\n",
    "\n",
    "train_dataset, validation_dataset = data_provider.split(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the training dataset\n",
    "\n",
    "train_dataset.augmentors = [\n",
    "    RandomBrightness(),\n",
    "    RandomErodeDilate(),\n",
    "    RandomSharpen(),\n",
    "]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an activation layer\n",
    "\n",
    "def activation_layer(layer, activation: str=\"relu\", alpha: float=0.1) -> tf.Tensor:\n",
    "    \"\"\" Activation layer wrapper for LeakyReLU and ReLU activation functions\n",
    "    Args:\n",
    "        layer: tf.Tensor\n",
    "        activation: str, activation function name (default: 'relu')\n",
    "        alpha: float (LeakyReLU activation function parameter)\n",
    "    Returns:\n",
    "        tf.Tensor\n",
    "    \"\"\"\n",
    "    if activation == \"relu\":\n",
    "        layer = layers.ReLU()(layer)\n",
    "    elif activation == \"leaky_relu\":\n",
    "        layer = layers.LeakyReLU(alpha=alpha)(layer)\n",
    "\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a residual block\n",
    "\n",
    "def residual_block(\n",
    "        x: tf.Tensor,\n",
    "        filter_num: int,\n",
    "        strides: typing.Union[int, list] = 2,\n",
    "        kernel_size: typing.Union[int, list] = 3,\n",
    "        skip_conv: bool = True,\n",
    "        padding: str = \"same\",\n",
    "        kernel_initializer: str = \"he_uniform\",\n",
    "        activation: str = \"relu\",\n",
    "        dropout: float = 0.2):\n",
    "    # Create skip connection tensor\n",
    "    x_skip = x\n",
    "\n",
    "    # Perform 1-st convolution\n",
    "    x = layers.Conv2D(filter_num, kernel_size, padding = padding, strides = strides, kernel_initializer=kernel_initializer)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = activation_layer(x, activation=activation)\n",
    "\n",
    "    # Perform 2-nd convolution\n",
    "    x = layers.Conv2D(filter_num, kernel_size, padding = padding, kernel_initializer=kernel_initializer)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Perform 3-rd convolution if skip_conv is True, matchin the number of filters and the shape of the skip connection tensor\n",
    "    if skip_conv:\n",
    "        x_skip = layers.Conv2D(filter_num, 1, padding = padding, strides = strides, kernel_initializer=kernel_initializer)(x_skip)\n",
    "\n",
    "    # Add x and skip connection and apply activation function\n",
    "    x = layers.Add()([x, x_skip])     \n",
    "    x = activation_layer(x, activation=activation)\n",
    "\n",
    "    # Apply dropout\n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model architecture\n",
    "\n",
    "def build_model(input_dim, output_dim, activation=\"leaky_relu\", dropout=0.2):\n",
    "    \n",
    "    inputs = layers.Input(shape=input_dim, name=\"input\")\n",
    "\n",
    "    # normalize images here instead in preprocessing step\n",
    "    input = layers.Lambda(lambda x: x / 255)(inputs)\n",
    "\n",
    "    x1 = residual_block(input, 32, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
    "\n",
    "    x2 = residual_block(x1, 32, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x3 = residual_block(x2, 32, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    x4 = residual_block(x3, 64, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x5 = residual_block(x4, 64, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    x6 = residual_block(x5, 128, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x7 = residual_block(x6, 128, activation=activation, skip_conv=True, strides=1, dropout=dropout)\n",
    "\n",
    "    x8 = residual_block(x7, 128, activation=activation, skip_conv=True, strides=2, dropout=dropout)\n",
    "    x9 = residual_block(x8, 128, activation=activation, skip_conv=False, strides=1, dropout=dropout)\n",
    "\n",
    "    squeezed = layers.Reshape((x9.shape[-3] * x9.shape[-2], x9.shape[-1]))(x9)\n",
    "\n",
    "    blstm = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(squeezed)\n",
    "    blstm = layers.Dropout(dropout)(blstm)\n",
    "\n",
    "    blstm = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(blstm)\n",
    "    blstm = layers.Dropout(dropout)(blstm)\n",
    "\n",
    "    output = layers.Dense(output_dim + 1, activation=\"softmax\", name=\"output\")(blstm)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a model\n",
    "\n",
    "model = build_model(\n",
    "    input_dim = (configs.height, configs.width, configs.channels),\n",
    "    output_dim = len(configs.vocab),\n",
    "    activation = \"leaky_relu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "______________________________________________________________________________________________________________\n",
      " Layer (type)                    Output Shape                     Param #    Connected to                     \n",
      "==============================================================================================================\n",
      " input (InputLayer)              [(None, 96, 1408, 3)]            0          []                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                              \n",
      " lambda (Lambda)                 (None, 96, 1408, 3)              0          ['input[0][0]']                  \n",
      "                                                                                                              \n",
      " conv2d (Conv2D)                 (None, 96, 1408, 32)             896        ['lambda[0][0]']                 \n",
      "                                                                                                              \n",
      " batch_normalization (BatchNorm  (None, 96, 1408, 32)             128        ['conv2d[0][0]']                 \n",
      " alization)                                                                                                   \n",
      "                                                                                                              \n",
      " leaky_re_lu (LeakyReLU)         (None, 96, 1408, 32)             0          ['batch_normalization[0][0]']    \n",
      "                                                                                                              \n",
      " conv2d_1 (Conv2D)               (None, 96, 1408, 32)             9248       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                              \n",
      " batch_normalization_1 (BatchNo  (None, 96, 1408, 32)             128        ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " conv2d_2 (Conv2D)               (None, 96, 1408, 32)             128        ['lambda[0][0]']                 \n",
      "                                                                                                              \n",
      " add (Add)                       (None, 96, 1408, 32)             0          ['batch_normalization_1[0][0]',  \n",
      "                                                                              'conv2d_2[0][0]']               \n",
      "                                                                                                              \n",
      " leaky_re_lu_1 (LeakyReLU)       (None, 96, 1408, 32)             0          ['add[0][0]']                    \n",
      "                                                                                                              \n",
      " dropout (Dropout)               (None, 96, 1408, 32)             0          ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_3 (Conv2D)               (None, 48, 704, 32)              9248       ['dropout[0][0]']                \n",
      "                                                                                                              \n",
      " batch_normalization_2 (BatchNo  (None, 48, 704, 32)              128        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " leaky_re_lu_2 (LeakyReLU)       (None, 48, 704, 32)              0          ['batch_normalization_2[0][0]']  \n",
      "                                                                                                              \n",
      " conv2d_4 (Conv2D)               (None, 48, 704, 32)              9248       ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                              \n",
      " batch_normalization_3 (BatchNo  (None, 48, 704, 32)              128        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " conv2d_5 (Conv2D)               (None, 48, 704, 32)              1056       ['dropout[0][0]']                \n",
      "                                                                                                              \n",
      " add_1 (Add)                     (None, 48, 704, 32)              0          ['batch_normalization_3[0][0]',  \n",
      "                                                                              'conv2d_5[0][0]']               \n",
      "                                                                                                              \n",
      " leaky_re_lu_3 (LeakyReLU)       (None, 48, 704, 32)              0          ['add_1[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_1 (Dropout)             (None, 48, 704, 32)              0          ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_6 (Conv2D)               (None, 48, 704, 32)              9248       ['dropout_1[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_4 (BatchNo  (None, 48, 704, 32)              128        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " leaky_re_lu_4 (LeakyReLU)       (None, 48, 704, 32)              0          ['batch_normalization_4[0][0]']  \n",
      "                                                                                                              \n",
      " conv2d_7 (Conv2D)               (None, 48, 704, 32)              9248       ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                              \n",
      " batch_normalization_5 (BatchNo  (None, 48, 704, 32)              128        ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " add_2 (Add)                     (None, 48, 704, 32)              0          ['batch_normalization_5[0][0]',  \n",
      "                                                                              'dropout_1[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_5 (LeakyReLU)       (None, 48, 704, 32)              0          ['add_2[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_2 (Dropout)             (None, 48, 704, 32)              0          ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_8 (Conv2D)               (None, 24, 352, 64)              18496      ['dropout_2[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_6 (BatchNo  (None, 24, 352, 64)              256        ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " leaky_re_lu_6 (LeakyReLU)       (None, 24, 352, 64)              0          ['batch_normalization_6[0][0]']  \n",
      "                                                                                                              \n",
      " conv2d_9 (Conv2D)               (None, 24, 352, 64)              36928      ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                              \n",
      " batch_normalization_7 (BatchNo  (None, 24, 352, 64)              256        ['conv2d_9[0][0]']               \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " conv2d_10 (Conv2D)              (None, 24, 352, 64)              2112       ['dropout_2[0][0]']              \n",
      "                                                                                                              \n",
      " add_3 (Add)                     (None, 24, 352, 64)              0          ['batch_normalization_7[0][0]',  \n",
      "                                                                              'conv2d_10[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_7 (LeakyReLU)       (None, 24, 352, 64)              0          ['add_3[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_3 (Dropout)             (None, 24, 352, 64)              0          ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_11 (Conv2D)              (None, 24, 352, 64)              36928      ['dropout_3[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_8 (BatchNo  (None, 24, 352, 64)              256        ['conv2d_11[0][0]']              \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " leaky_re_lu_8 (LeakyReLU)       (None, 24, 352, 64)              0          ['batch_normalization_8[0][0]']  \n",
      "                                                                                                              \n",
      " conv2d_12 (Conv2D)              (None, 24, 352, 64)              36928      ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                              \n",
      " batch_normalization_9 (BatchNo  (None, 24, 352, 64)              256        ['conv2d_12[0][0]']              \n",
      " rmalization)                                                                                                 \n",
      "                                                                                                              \n",
      " add_4 (Add)                     (None, 24, 352, 64)              0          ['batch_normalization_9[0][0]',  \n",
      "                                                                              'dropout_3[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_9 (LeakyReLU)       (None, 24, 352, 64)              0          ['add_4[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_4 (Dropout)             (None, 24, 352, 64)              0          ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                              \n",
      " conv2d_13 (Conv2D)              (None, 12, 176, 128)             73856      ['dropout_4[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_10 (BatchN  (None, 12, 176, 128)             512        ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_10 (LeakyReLU)      (None, 12, 176, 128)             0          ['batch_normalization_10[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_14 (Conv2D)              (None, 12, 176, 128)             147584     ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_11 (BatchN  (None, 12, 176, 128)             512        ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_15 (Conv2D)              (None, 12, 176, 128)             8320       ['dropout_4[0][0]']              \n",
      "                                                                                                              \n",
      " add_5 (Add)                     (None, 12, 176, 128)             0          ['batch_normalization_11[0][0]', \n",
      "                                                                              'conv2d_15[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_11 (LeakyReLU)      (None, 12, 176, 128)             0          ['add_5[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_5 (Dropout)             (None, 12, 176, 128)             0          ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_16 (Conv2D)              (None, 12, 176, 128)             147584     ['dropout_5[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_12 (BatchN  (None, 12, 176, 128)             512        ['conv2d_16[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_12 (LeakyReLU)      (None, 12, 176, 128)             0          ['batch_normalization_12[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_17 (Conv2D)              (None, 12, 176, 128)             147584     ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_13 (BatchN  (None, 12, 176, 128)             512        ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_18 (Conv2D)              (None, 12, 176, 128)             16512      ['dropout_5[0][0]']              \n",
      "                                                                                                              \n",
      " add_6 (Add)                     (None, 12, 176, 128)             0          ['batch_normalization_13[0][0]', \n",
      "                                                                              'conv2d_18[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_13 (LeakyReLU)      (None, 12, 176, 128)             0          ['add_6[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_6 (Dropout)             (None, 12, 176, 128)             0          ['leaky_re_lu_13[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_19 (Conv2D)              (None, 6, 88, 128)               147584     ['dropout_6[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_14 (BatchN  (None, 6, 88, 128)               512        ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_14 (LeakyReLU)      (None, 6, 88, 128)               0          ['batch_normalization_14[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_20 (Conv2D)              (None, 6, 88, 128)               147584     ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_15 (BatchN  (None, 6, 88, 128)               512        ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " conv2d_21 (Conv2D)              (None, 6, 88, 128)               16512      ['dropout_6[0][0]']              \n",
      "                                                                                                              \n",
      " add_7 (Add)                     (None, 6, 88, 128)               0          ['batch_normalization_15[0][0]', \n",
      "                                                                              'conv2d_21[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_15 (LeakyReLU)      (None, 6, 88, 128)               0          ['add_7[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_7 (Dropout)             (None, 6, 88, 128)               0          ['leaky_re_lu_15[0][0]']         \n",
      "                                                                                                              \n",
      " conv2d_22 (Conv2D)              (None, 6, 88, 128)               147584     ['dropout_7[0][0]']              \n",
      "                                                                                                              \n",
      " batch_normalization_16 (BatchN  (None, 6, 88, 128)               512        ['conv2d_22[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " leaky_re_lu_16 (LeakyReLU)      (None, 6, 88, 128)               0          ['batch_normalization_16[0][0]'] \n",
      "                                                                                                              \n",
      " conv2d_23 (Conv2D)              (None, 6, 88, 128)               147584     ['leaky_re_lu_16[0][0]']         \n",
      "                                                                                                              \n",
      " batch_normalization_17 (BatchN  (None, 6, 88, 128)               512        ['conv2d_23[0][0]']              \n",
      " ormalization)                                                                                                \n",
      "                                                                                                              \n",
      " add_8 (Add)                     (None, 6, 88, 128)               0          ['batch_normalization_17[0][0]', \n",
      "                                                                              'dropout_7[0][0]']              \n",
      "                                                                                                              \n",
      " leaky_re_lu_17 (LeakyReLU)      (None, 6, 88, 128)               0          ['add_8[0][0]']                  \n",
      "                                                                                                              \n",
      " dropout_8 (Dropout)             (None, 6, 88, 128)               0          ['leaky_re_lu_17[0][0]']         \n",
      "                                                                                                              \n",
      " reshape (Reshape)               (None, 528, 128)                 0          ['dropout_8[0][0]']              \n",
      "                                                                                                              \n",
      " bidirectional (Bidirectional)   (None, 528, 512)                 788480     ['reshape[0][0]']                \n",
      "                                                                                                              \n",
      " dropout_9 (Dropout)             (None, 528, 512)                 0          ['bidirectional[0][0]']          \n",
      "                                                                                                              \n",
      " bidirectional_1 (Bidirectional  (None, 528, 128)                 295424     ['dropout_9[0][0]']              \n",
      " )                                                                                                            \n",
      "                                                                                                              \n",
      " dropout_10 (Dropout)            (None, 528, 128)                 0          ['bidirectional_1[0][0]']        \n",
      "                                                                                                              \n",
      " output (Dense)                  (None, 528, 80)                  10320      ['dropout_10[0][0]']             \n",
      "                                                                                                              \n",
      "==============================================================================================================\n",
      "Total params: 2428112 (9.26 MB)\n",
      "Trainable params: 2425168 (9.25 MB)\n",
      "Non-trainable params: 2944 (11.50 KB)\n",
      "______________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# compile the model and print the summary\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=configs.learning_rate), \n",
    "    loss=CTCloss(), \n",
    "    metrics=[\n",
    "        CERMetric(vocabulary=configs.vocab),\n",
    "        WERMetric(vocabulary=configs.vocab)\n",
    "        ],\n",
    "    run_eagerly=False\n",
    ")\n",
    "model.summary(line_length=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf2onnx\\tf_loader.py:69: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf2onnx\\tf_loader.py:73: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define callbacks\n",
    "\n",
    "earlystopper = EarlyStopping(monitor=\"val_CER\", patience=20, verbose=1, mode=\"min\")\n",
    "checkpoint = ModelCheckpoint(f\"{configs.model_path}/model.h5\", monitor=\"val_CER\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "trainLogger = TrainLogger(configs.model_path)\n",
    "tb_callback = TensorBoard(f\"{configs.model_path}/logs\", update_freq=1)\n",
    "reduceLROnPlat = ReduceLROnPlateau(monitor=\"val_CER\", factor=0.9, min_delta=1e-10, patience=5, verbose=1, mode=\"auto\")\n",
    "model2onnx = Model2onnx(f\"{configs.model_path}/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:From c:\\Users\\Dell\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "  4/472 [..............................] - ETA: 8:56:07 - loss: 1356.7601 - CER: 4.1739 - WER: 1.0267"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=validation_dataset,\n",
    "    epochs=configs.train_epochs,\n",
    "    callbacks=[earlystopper, checkpoint, trainLogger, tb_callback, reduceLROnPlat, model2onnx],\n",
    "    verbose=1,\n",
    "    workers=configs.train_workers,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
